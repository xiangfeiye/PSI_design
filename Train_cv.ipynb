{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf9d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc79cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\conda\\envs\\py311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = int(32*trial.suggest_float(\"n_estimators\", 2, 16, step=1))\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.20, step=0.01)\n",
    "    max_depth = int(trial.suggest_float(\"max_depth\", 1, 5, step=1))\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1, step=0.05)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42,\n",
    "        loss='squared_error', subsample=subsample).fit(X_train, y_train)\n",
    "    score = np.abs(mean_absolute_error(y_test, model.predict(X_test)) - mean_absolute_error(y_train, model.predict(X_train))) - r2_score(y_test, model.predict(X_test))\n",
    "    return score\n",
    "\n",
    "def objective_cv(trial):\n",
    "    n_estimators = int(32*trial.suggest_float(\"n_estimators\", 2, 16, step=1))\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.20, step=0.01)\n",
    "    max_depth = int(trial.suggest_float(\"max_depth\", 1, 5, step=1))\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1, step=0.05)\n",
    "    \n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42,\n",
    "        loss='squared_error', subsample=subsample).fit(X_train, y_train)\n",
    "    score = -1 * (cross_validate(model, X_std, Y_std, cv=5)['test_score'].mean())\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b08d03d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-25 11:18:46,271] A new study created in memory with name: no-name-0bd2efa2-4a5d-4f1d-aa59-851f18e87958\n",
      "[I 2024-07-25 11:18:47,652] Trial 0 finished with value: -0.5211468191111048 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.09, 'max_depth': 2.0, 'subsample': 0.75}. Best is trial 0 with value: -0.5211468191111048.\n",
      "[I 2024-07-25 11:18:49,134] Trial 1 finished with value: -0.5231615645104772 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.14, 'max_depth': 3.0, 'subsample': 0.8500000000000001}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:50,360] Trial 2 finished with value: -0.49751193219606443 and parameters: {'n_estimators': 4.0, 'learning_rate': 0.08, 'max_depth': 5.0, 'subsample': 0.7}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:51,030] Trial 3 finished with value: -0.3173645670835995 and parameters: {'n_estimators': 4.0, 'learning_rate': 0.01, 'max_depth': 2.0, 'subsample': 0.7}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:52,286] Trial 4 finished with value: -0.46526008132372054 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.12, 'max_depth': 3.0, 'subsample': 0.55}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:53,759] Trial 5 finished with value: -0.5221678487221403 and parameters: {'n_estimators': 13.0, 'learning_rate': 0.19, 'max_depth': 1.0, 'subsample': 0.7}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:55,369] Trial 6 finished with value: -0.5056603244989958 and parameters: {'n_estimators': 15.0, 'learning_rate': 0.04, 'max_depth': 1.0, 'subsample': 0.65}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:18:56,994] Trial 7 finished with value: -0.5019761744840687 and parameters: {'n_estimators': 15.0, 'learning_rate': 0.09999999999999999, 'max_depth': 1.0, 'subsample': 0.65}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:01,619] Trial 8 finished with value: -0.5030210273890288 and parameters: {'n_estimators': 16.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.8}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:04,162] Trial 9 finished with value: -0.49109023663859724 and parameters: {'n_estimators': 12.0, 'learning_rate': 0.13, 'max_depth': 3.0, 'subsample': 0.7}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:05,002] Trial 10 finished with value: -0.5035627954742667 and parameters: {'n_estimators': 2.0, 'learning_rate': 0.17, 'max_depth': 5.0, 'subsample': 1.0}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:07,102] Trial 11 finished with value: -0.5011932045902239 and parameters: {'n_estimators': 11.0, 'learning_rate': 0.2, 'max_depth': 2.0, 'subsample': 0.9}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:10,753] Trial 12 finished with value: -0.4819930247733855 and parameters: {'n_estimators': 12.0, 'learning_rate': 0.16, 'max_depth': 4.0, 'subsample': 0.8500000000000001}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:11,369] Trial 13 finished with value: -0.4931615231882388 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.2, 'max_depth': 1.0, 'subsample': 0.5}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:14,705] Trial 14 finished with value: -0.4960718824439859 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.15000000000000002, 'max_depth': 4.0, 'subsample': 0.95}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:17,149] Trial 15 finished with value: -0.496650132307468 and parameters: {'n_estimators': 13.0, 'learning_rate': 0.18000000000000002, 'max_depth': 2.0, 'subsample': 0.8500000000000001}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:18,164] Trial 16 finished with value: -0.5076698351640452 and parameters: {'n_estimators': 5.0, 'learning_rate': 0.14, 'max_depth': 3.0, 'subsample': 0.6}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:19,363] Trial 17 finished with value: -0.512448046543136 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.18000000000000002, 'max_depth': 1.0, 'subsample': 0.8}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:19,928] Trial 18 finished with value: -0.4962376626723028 and parameters: {'n_estimators': 2.0, 'learning_rate': 0.11, 'max_depth': 3.0, 'subsample': 0.9}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:22,511] Trial 19 finished with value: -0.5045832188659581 and parameters: {'n_estimators': 14.0, 'learning_rate': 0.15000000000000002, 'max_depth': 2.0, 'subsample': 0.8}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:25,691] Trial 20 finished with value: -0.4492439103838322 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.2, 'max_depth': 4.0, 'subsample': 1.0}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:27,061] Trial 21 finished with value: -0.5211468191111048 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.09, 'max_depth': 2.0, 'subsample': 0.75}. Best is trial 1 with value: -0.5231615645104772.\n",
      "[I 2024-07-25 11:19:28,262] Trial 22 finished with value: -0.5253903582501194 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.06999999999999999, 'max_depth': 2.0, 'subsample': 0.75}. Best is trial 22 with value: -0.5253903582501194.\n",
      "[I 2024-07-25 11:19:29,013] Trial 23 finished with value: -0.47972205637406357 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.05, 'max_depth': 1.0, 'subsample': 0.8500000000000001}. Best is trial 22 with value: -0.5253903582501194.\n",
      "[I 2024-07-25 11:19:30,441] Trial 24 finished with value: -0.5254695320985521 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.06999999999999999, 'max_depth': 3.0, 'subsample': 0.65}. Best is trial 24 with value: -0.5254695320985521.\n",
      "[I 2024-07-25 11:19:31,809] Trial 25 finished with value: -0.5156469832969802 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.06999999999999999, 'max_depth': 3.0, 'subsample': 0.6}. Best is trial 24 with value: -0.5254695320985521.\n",
      "[I 2024-07-25 11:19:32,637] Trial 26 finished with value: -0.4970516566656544 and parameters: {'n_estimators': 4.0, 'learning_rate': 0.03, 'max_depth': 3.0, 'subsample': 0.65}. Best is trial 24 with value: -0.5254695320985521.\n",
      "[I 2024-07-25 11:19:34,314] Trial 27 finished with value: -0.5277112654486132 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.06999999999999999, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:36,188] Trial 28 finished with value: -0.5134131305416234 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.02, 'max_depth': 4.0, 'subsample': 0.6}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:39,474] Trial 29 finished with value: -0.5052041666666277 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.06999999999999999, 'max_depth': 5.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:41,409] Trial 30 finished with value: -0.5103260215055516 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.05, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:42,608] Trial 31 finished with value: -0.5180009046013666 and parameters: {'n_estimators': 5.0, 'learning_rate': 0.09, 'max_depth': 3.0, 'subsample': 0.8}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:43,770] Trial 32 finished with value: -0.519354364726475 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.08, 'max_depth': 2.0, 'subsample': 0.9}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:44,421] Trial 33 finished with value: -0.5274240219100499 and parameters: {'n_estimators': 3.0, 'learning_rate': 0.11, 'max_depth': 3.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:45,243] Trial 34 finished with value: -0.5164181473838964 and parameters: {'n_estimators': 3.0, 'learning_rate': 0.11, 'max_depth': 4.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-25 11:19:45,870] Trial 35 finished with value: -0.5189668084502097 and parameters: {'n_estimators': 3.0, 'learning_rate': 0.06999999999999999, 'max_depth': 3.0, 'subsample': 0.65}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:46,709] Trial 36 finished with value: -0.5141687706182356 and parameters: {'n_estimators': 5.0, 'learning_rate': 0.09999999999999999, 'max_depth': 2.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:48,521] Trial 37 finished with value: -0.49234969483815494 and parameters: {'n_estimators': 7.0, 'learning_rate': 0.08, 'max_depth': 5.0, 'subsample': 0.55}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:49,391] Trial 38 finished with value: -0.5146693351823333 and parameters: {'n_estimators': 4.0, 'learning_rate': 0.12, 'max_depth': 3.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:50,026] Trial 39 finished with value: -0.49810605978141903 and parameters: {'n_estimators': 3.0, 'learning_rate': 0.04, 'max_depth': 3.0, 'subsample': 0.65}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:52,264] Trial 40 finished with value: -0.5268464115672368 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:54,480] Trial 41 finished with value: -0.5268464115672368 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:19:56,690] Trial 42 finished with value: -0.509879164447229 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.05, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:00,156] Trial 43 finished with value: -0.5104519507454305 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.060000000000000005, 'max_depth': 5.0, 'subsample': 0.8}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:02,523] Trial 44 finished with value: -0.49247526851732093 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.01, 'max_depth': 4.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:03,933] Trial 45 finished with value: -0.5226130446025692 and parameters: {'n_estimators': 5.0, 'learning_rate': 0.03, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:05,926] Trial 46 finished with value: -0.5264217554113058 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.09, 'max_depth': 4.0, 'subsample': 0.65}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:08,427] Trial 47 finished with value: -0.49849355461373135 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.09, 'max_depth': 5.0, 'subsample': 0.7}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:11,687] Trial 48 finished with value: -0.49556843682192275 and parameters: {'n_estimators': 11.0, 'learning_rate': 0.12, 'max_depth': 4.0, 'subsample': 0.8}. Best is trial 27 with value: -0.5277112654486132.\n",
      "[I 2024-07-25 11:20:13,821] Trial 49 finished with value: -0.5279888665031633 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.6}. Best is trial 49 with value: -0.5279888665031633.\n",
      "[I 2024-07-25 11:20:16,874] Trial 50 finished with value: -0.521908523617285 and parameters: {'n_estimators': 11.0, 'learning_rate': 0.060000000000000005, 'max_depth': 5.0, 'subsample': 0.6}. Best is trial 49 with value: -0.5279888665031633.\n",
      "[I 2024-07-25 11:20:18,753] Trial 51 finished with value: -0.4937990040825445 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.08, 'max_depth': 4.0, 'subsample': 0.5}. Best is trial 49 with value: -0.5279888665031633.\n",
      "[I 2024-07-25 11:20:20,523] Trial 52 finished with value: -0.5125990807071953 and parameters: {'n_estimators': 8.0, 'learning_rate': 0.09999999999999999, 'max_depth': 4.0, 'subsample': 0.55}. Best is trial 49 with value: -0.5279888665031633.\n",
      "[I 2024-07-25 11:20:22,796] Trial 53 finished with value: -0.5327097188702405 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.04, 'max_depth': 4.0, 'subsample': 0.65}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:25,693] Trial 54 finished with value: -0.49924871940689997 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.04, 'max_depth': 4.0, 'subsample': 0.75}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:28,109] Trial 55 finished with value: -0.5270190237049037 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.03, 'max_depth': 4.0, 'subsample': 0.6}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:30,907] Trial 56 finished with value: -0.5265541870634121 and parameters: {'n_estimators': 12.0, 'learning_rate': 0.03, 'max_depth': 4.0, 'subsample': 0.6}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:33,420] Trial 57 finished with value: -0.5079191851223549 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.02, 'max_depth': 5.0, 'subsample': 0.6}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:35,235] Trial 58 finished with value: -0.5238399608435635 and parameters: {'n_estimators': 10.0, 'learning_rate': 0.04, 'max_depth': 3.0, 'subsample': 0.55}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:37,647] Trial 59 finished with value: -0.5185135327320498 and parameters: {'n_estimators': 11.0, 'learning_rate': 0.02, 'max_depth': 4.0, 'subsample': 0.55}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:38,157] Trial 60 finished with value: -0.5182634648422118 and parameters: {'n_estimators': 2.0, 'learning_rate': 0.05, 'max_depth': 4.0, 'subsample': 0.65}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:40,520] Trial 61 finished with value: -0.5091004388191909 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.7}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:42,869] Trial 62 finished with value: -0.5091004388191909 and parameters: {'n_estimators': 9.0, 'learning_rate': 0.060000000000000005, 'max_depth': 4.0, 'subsample': 0.7}. Best is trial 53 with value: -0.5327097188702405.\n",
      "[I 2024-07-25 11:20:44,377] Trial 63 finished with value: -0.5227722661967772 and parameters: {'n_estimators': 6.0, 'learning_rate': 0.05, 'max_depth': 4.0, 'subsample': 0.65}. Best is trial 53 with value: -0.5327097188702405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11223992115986102 0.2903794770959174\n",
      "0.019557755023546022 0.16634566036792608\n",
      "0.13984904369907583 0.40785495015743783\n",
      "0.9813813932336299 0.7908770035018319\n"
     ]
    }
   ],
   "source": [
    "# cross valid\n",
    "path = './sp_p/'\n",
    "df_name = 'SP_P_clean_des_977_256_41_15.csv'\n",
    "df = pd.read_csv(path+df_name)\n",
    "X = np.array(df.iloc[:,:-1], dtype=float)\n",
    "Y = np.array(df.iloc[:,-1], dtype=float)\n",
    "\n",
    "x_mean = np.nanmean(X, axis=0)\n",
    "x_std = np.nanstd(X, axis=0)\n",
    "y_mean = np.nanmean(Y, axis=0)\n",
    "y_std = np.nanstd(Y, axis=0)\n",
    "\n",
    "X_std = (X-x_mean)/(1e-9+x_std)\n",
    "Y_std = (Y-y_mean)/(1e-9+y_std)\n",
    "X_std[np.isnan(X_std)] = 0\n",
    "Y_std[np.isnan(Y_std)] = 0\n",
    "\n",
    "ratio = 0.8\n",
    "size = int(ratio* len(df))\n",
    "\n",
    "X_train, X_test = X_std[:size], X_std[size:]\n",
    "y_train, y_test = Y_std[:size], Y_std[size:]\n",
    "\n",
    "est = GradientBoostingRegressor(\n",
    "    n_estimators=256, learning_rate=0.1, max_depth=3, random_state=42,\n",
    "    loss='squared_error', subsample=0.9).fit(X_train, y_train)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective_cv, n_trials=64)\n",
    "\n",
    "est = GradientBoostingRegressor(\n",
    "        n_estimators=int(study.best_params['n_estimators']*32),\n",
    "        learning_rate=study.best_params['learning_rate'],\n",
    "        max_depth=int(study.best_params['max_depth']),\n",
    "        random_state=42,\n",
    "        loss='squared_error',\n",
    "        subsample=study.best_params['subsample']\n",
    ").fit(X_train, y_train)\n",
    "print(mean_absolute_error(y_train, est.predict(X_train)), mean_absolute_error(y_test, est.predict(X_test)))\n",
    "print(mean_squared_error(y_train, est.predict(X_train)), mean_squared_error(y_test, est.predict(X_test)))\n",
    "print(np.sqrt(mean_squared_error(y_train, est.predict(X_train))), np.sqrt(mean_squared_error(y_test, est.predict(X_test))))\n",
    "print(r2_score(y_train, est.predict(X_train)), r2_score(y_test, est.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70c9b905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5327097188702405 0.20829122205320896\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(est, X_std, Y_std, cv=5)['test_score']\n",
    "print(scores.mean(),scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345025ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
